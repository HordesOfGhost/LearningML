{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ghost\\AppData\\Local\\Temp\\ipykernel_11364\\437825376.py:35: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data=data.append(dataFrameFromDirectory('C:\\\\Users\\\\Ghost\\\\Desktop\\\\LearningML\\\\materials\\\\emails\\\\spam','spam'))\n",
      "C:\\Users\\Ghost\\AppData\\Local\\Temp\\ipykernel_11364\\437825376.py:36: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data=data.append(dataFrameFromDirectory('C:\\\\Users\\\\Ghost\\\\Desktop\\\\LearningML\\\\materials\\\\emails\\\\ham','ham'))\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import io\n",
    "import numpy as np\n",
    "from pandas import DataFrame\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "def readFile(path):\n",
    "    for root,dirname,filenames in os.walk(path):\n",
    "        for filename in filenames:\n",
    "            path=os.path.join(root,filename)\n",
    "            \n",
    "            inBody=False\n",
    "            lines=[]\n",
    "            f=io.open(path,'r',encoding='latin1')\n",
    "            for line in f:\n",
    "                if inBody:\n",
    "                    lines.append(line)\n",
    "                elif line== '\\n':\n",
    "                    inBody=True\n",
    "            f.close()\n",
    "            message='\\n'.join(lines)\n",
    "            yield path,message\n",
    "\n",
    "def dataFrameFromDirectory(path,classification):\n",
    "    rows=[]\n",
    "    index=[]\n",
    "    for filename,message in readFile(path):\n",
    "        rows.append({'message':message,'class':classification})\n",
    "        index.append(filename)\n",
    "        \n",
    "    return DataFrame(rows,index=index)\n",
    "data=DataFrame({'message':[],'class':[]})\n",
    "\n",
    "data=data.append(dataFrameFromDirectory('C:\\\\Users\\\\Ghost\\\\Desktop\\\\LearningML\\\\materials\\\\emails\\\\spam','spam'))\n",
    "data=data.append(dataFrameFromDirectory('C:\\\\Users\\\\Ghost\\\\Desktop\\\\LearningML\\\\materials\\\\emails\\\\ham','ham'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                              message  \\\n",
      "C:\\Users\\Ghost\\Desktop\\LearningML\\materials\\ema...  <!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 4.0 Tr...   \n",
      "C:\\Users\\Ghost\\Desktop\\LearningML\\materials\\ema...  1) Fight The Risk of Cancer!\\n\\nhttp://www.adc...   \n",
      "C:\\Users\\Ghost\\Desktop\\LearningML\\materials\\ema...  1) Fight The Risk of Cancer!\\n\\nhttp://www.adc...   \n",
      "C:\\Users\\Ghost\\Desktop\\LearningML\\materials\\ema...  ##############################################...   \n",
      "C:\\Users\\Ghost\\Desktop\\LearningML\\materials\\ema...  I thought you might like these:\\n\\n1) Slim Dow...   \n",
      "...                                                                                               ...   \n",
      "C:\\Users\\Ghost\\Desktop\\LearningML\\materials\\ema...  Man killed 'trying to surf' on Tube train \\n\\n...   \n",
      "C:\\Users\\Ghost\\Desktop\\LearningML\\materials\\ema...  Hi Gianni,\\n\\n\\n\\nA very good resource for thi...   \n",
      "C:\\Users\\Ghost\\Desktop\\LearningML\\materials\\ema...  Gianni Ponzi wrote:\\n\\n> I have a prob when tr...   \n",
      "C:\\Users\\Ghost\\Desktop\\LearningML\\materials\\ema...  Neale Pickett <neale@woozle.org> writes:\\n\\n\\n...   \n",
      "C:\\Users\\Ghost\\Desktop\\LearningML\\materials\\ema...  \\n\\nHi,\\n\\n\\n\\nI think you need to give us a l...   \n",
      "\n",
      "                                                   class  \n",
      "C:\\Users\\Ghost\\Desktop\\LearningML\\materials\\ema...  spam  \n",
      "C:\\Users\\Ghost\\Desktop\\LearningML\\materials\\ema...  spam  \n",
      "C:\\Users\\Ghost\\Desktop\\LearningML\\materials\\ema...  spam  \n",
      "C:\\Users\\Ghost\\Desktop\\LearningML\\materials\\ema...  spam  \n",
      "C:\\Users\\Ghost\\Desktop\\LearningML\\materials\\ema...  spam  \n",
      "...                                                  ...  \n",
      "C:\\Users\\Ghost\\Desktop\\LearningML\\materials\\ema...   ham  \n",
      "C:\\Users\\Ghost\\Desktop\\LearningML\\materials\\ema...   ham  \n",
      "C:\\Users\\Ghost\\Desktop\\LearningML\\materials\\ema...   ham  \n",
      "C:\\Users\\Ghost\\Desktop\\LearningML\\materials\\ema...   ham  \n",
      "C:\\Users\\Ghost\\Desktop\\LearningML\\materials\\ema...   ham  \n",
      "\n",
      "[3000 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 20407)\t1\n",
      "  (0, 28844)\t5\n",
      "  (0, 44554)\t1\n",
      "  (0, 57486)\t1\n",
      "  (0, 21111)\t1\n",
      "  (0, 54131)\t1\n",
      "  (0, 22319)\t1\n",
      "  (0, 27856)\t2\n",
      "  (0, 36946)\t2\n",
      "  (0, 17466)\t2\n",
      "  (0, 3669)\t28\n",
      "  (0, 53112)\t1\n",
      "  (0, 15912)\t1\n",
      "  (0, 3865)\t1\n",
      "  (0, 1193)\t1\n",
      "  (0, 28855)\t2\n",
      "  (0, 22714)\t1\n",
      "  (0, 3777)\t1\n",
      "  (0, 60830)\t1\n",
      "  (0, 38010)\t1\n",
      "  (0, 0)\t1\n",
      "  (0, 2507)\t1\n",
      "  (0, 878)\t1\n",
      "  (0, 38606)\t1\n",
      "  (0, 3793)\t1\n",
      "  :\t:\n",
      "  (2999, 46468)\t2\n",
      "  (2999, 59145)\t1\n",
      "  (2999, 13966)\t1\n",
      "  (2999, 43537)\t2\n",
      "  (2999, 51993)\t2\n",
      "  (2999, 51125)\t1\n",
      "  (2999, 52000)\t1\n",
      "  (2999, 19003)\t1\n",
      "  (2999, 19930)\t1\n",
      "  (2999, 25894)\t1\n",
      "  (2999, 44095)\t3\n",
      "  (2999, 44115)\t1\n",
      "  (2999, 19929)\t1\n",
      "  (2999, 27117)\t1\n",
      "  (2999, 19932)\t1\n",
      "  (2999, 20051)\t1\n",
      "  (2999, 13397)\t2\n",
      "  (2999, 19778)\t1\n",
      "  (2999, 25157)\t1\n",
      "  (2999, 46316)\t1\n",
      "  (2999, 30662)\t2\n",
      "  (2999, 3103)\t1\n",
      "  (2999, 26274)\t1\n",
      "  (2999, 43488)\t1\n",
      "  (2999, 8396)\t1\n"
     ]
    }
   ],
   "source": [
    "# using CountVectorizer to split msg into its list of words\n",
    "vectorizer=CountVectorizer()\n",
    "counts=vectorizer.fit_transform(data['message'].values)\n",
    "\n",
    "classifier=MultinomialNB()\n",
    "targets=data['class'].values\n",
    "\n",
    "classifier.fit(counts,targets)\n",
    "print (counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ham' 'spam' 'ham' 'ham']\n"
     ]
    }
   ],
   "source": [
    "examples=['Hello and thank you for staying with us!','Free sales','Call Me','Hi Bob,how about a game of golf tommorrow?']\n",
    "example_counts=vectorizer.transform(examples)\n",
    "predictions=classifier.predict(example_counts)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('class')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2ab26ebc9eac352ad84074c5872f53e9ff2d0f751ba36ba2a556974c64f5628d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
